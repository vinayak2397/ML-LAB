{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75d7d1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree for the dataset using ID3 algorithm is :\n",
      "\n",
      " Outlook \n",
      "   └─ Sunny\n",
      "     Humidity \n",
      "       └─ Normal\n",
      "         Yes\n",
      "       └─ High\n",
      "         No\n",
      "   └─ Overcast\n",
      "     Yes\n",
      "   └─ Rain\n",
      "     Wind \n",
      "       └─ Weak\n",
      "         Yes\n",
      "       └─ Strong\n",
      "         No\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import csv\n",
    "def load_csv(filename):\n",
    "    lines=csv.reader(open(filename,\"r\"));\n",
    "    dataset = list(lines)\n",
    "    headers = dataset.pop(0)\n",
    "    return dataset,headers\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,attribute):\n",
    "        self.attribute=attribute\n",
    "        self.children=[]\n",
    "        self.answer=\"\"\n",
    "        \n",
    "def subtables(data,col,delete):\n",
    "    dic={}\n",
    "    coldata=[row[col] for row in data]\n",
    "    attr=list(set(coldata))\n",
    "    \n",
    "    counts=[0]*len(attr)\n",
    "    r=len(data)\n",
    "    c=len(data[0])\n",
    "    for x in range(len(attr)):\n",
    "        for y in range(r):\n",
    "            if data[y][col]==attr[x]:\n",
    "                counts[x]+=1\n",
    "        \n",
    "    for x in range(len(attr)):\n",
    "        dic[attr[x]]=[[0 for i in range(c)] for j in range(counts[x])]\n",
    "        pos=0\n",
    "        for y in range(r):\n",
    "            if data[y][col]==attr[x]:\n",
    "                if delete:\n",
    "                    del data[y][col]\n",
    "                dic[attr[x]][pos]=data[y]\n",
    "                pos+=1\n",
    "    return attr,dic\n",
    "    \n",
    "def entropy(S):\n",
    "    attr=list(set(S))\n",
    "    if len(attr)==1:\n",
    "        return 0\n",
    "    \n",
    "    counts=[0,0]\n",
    "    for i in range(2):\n",
    "        counts[i]=sum([1 for x in S if attr[i]==x])/(len(S)*1.0)\n",
    "    \n",
    "    sums=0\n",
    "    for cnt in counts:\n",
    "        sums+=-1*cnt*math.log(cnt,2)\n",
    "    return sums\n",
    "\n",
    "def compute_gain(data,col):\n",
    "    attr,dic = subtables(data,col,delete=False)\n",
    "    \n",
    "    total_size=len(data)\n",
    "    entropies=[0]*len(attr)\n",
    "    ratio=[0]*len(attr)\n",
    "    \n",
    "    total_entropy=entropy([row[-1] for row in data])\n",
    "    for x in range(len(attr)):\n",
    "        ratio[x]=len(dic[attr[x]])/(total_size*1.0)\n",
    "        entropies[x]=entropy([row[-1] for row in dic[attr[x]]])\n",
    "        total_entropy-=ratio[x]*entropies[x]\n",
    "    return total_entropy\n",
    "\n",
    "def build_tree(data,features):\n",
    "    lastcol=[row[-1] for row in data]\n",
    "    if(len(set(lastcol)))==1:\n",
    "        node=Node(\"\")\n",
    "        node.answer=lastcol[0]\n",
    "        return node\n",
    "    \n",
    "    n=len(data[0])-1\n",
    "    gains=[0]*n\n",
    "    for col in range(n):\n",
    "        gains[col]=compute_gain(data,col)\n",
    "    split=gains.index(max(gains))\n",
    "    node=Node(features[split])\n",
    "    fea = features[:split]+features[split+1:]\n",
    "\n",
    "    \n",
    "    attr,dic=subtables(data,split,delete=True)\n",
    "    \n",
    "    for x in range(len(attr)):\n",
    "        child=build_tree(dic[attr[x]],fea)\n",
    "        node.children.append((attr[x],child))\n",
    "    return node\n",
    "\n",
    "def print_tree(node,level):\n",
    "    if node.answer!=\"\":\n",
    "        print(\"  \"*level,node.answer)\n",
    "        return\n",
    "    \n",
    "    print(\"  \"*level,node.attribute)\n",
    "    for value,n in node.children:\n",
    "        print(\"  \"*(level+1),\"└─\",value)\n",
    "        print_tree(n,level+2)\n",
    "\n",
    "    \n",
    "'''Main program'''\n",
    "dataset,features=load_csv(\"data.csv\")\n",
    "node1=build_tree(dataset,features)\n",
    "\n",
    "print(\"The decision tree for the dataset using ID3 algorithm is :\\n\")\n",
    "print_tree(node1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60bcc92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The decision tree for the dataset using ID3 algorithm is :\n",
      "\n",
      " Heat_Treatment_Method\n",
      "   └─  Alloy_C15500_\n",
      "     FALSE\n",
      "   └─  FeP03 \n",
      "     FALSE\n",
      "   └─  Bronze_C90200_\n",
      "     FALSE\n",
      "   └─  Alloy_AM100A_T61 sand casting\n",
      "     FALSE\n",
      "   └─  Bronze_C90500_\n",
      "     FALSE\n",
      "   └─  Bronze_C95400_\n",
      "     FALSE\n",
      "   └─  Alloy_8176_H24 Wrought\n",
      "     FALSE\n",
      "   └─  S355JO \n",
      "     TRUE\n",
      "   └─  Alloy_C10100_\n",
      "     FALSE\n",
      "   └─  Alloy_3105_H18 Wrought\n",
      "     FALSE\n",
      "   └─  SAE_1015_normalized\n",
      "     TRUE\n",
      "   └─  FeP01 \n",
      "     FALSE\n",
      "   └─  Alloy_AZ81A_T4 sand casting\n",
      "     FALSE\n",
      "   └─  Bronze_C87400_\n",
      "     FALSE\n",
      "   └─  Bronze_C87500_\n",
      "     FALSE\n",
      "   └─  FeP04 \n",
      "     FALSE\n",
      "   └─ -Copper_Alloy_C81700 \n",
      "     FALSE\n",
      "   └─  cast_iron_\n",
      "     Strength\n",
      "       └─ 427\n",
      "         FALSE\n",
      "       └─ 538\n",
      "         FALSE\n",
      "       └─ 317\n",
      "         TRUE\n",
      "       └─ 365\n",
      "         FALSE\n",
      "       └─ 455\n",
      "         FALSE\n",
      "       └─ 207\n",
      "         FALSE\n",
      "       └─ 276\n",
      "         FALSE\n",
      "       └─ 552\n",
      "         FALSE\n",
      "   └─  Brass_C87200_\n",
      "     FALSE\n",
      "   └─  Alloy_C99500_\n",
      "     FALSE\n",
      "   └─  cast_iron_class 60 \n",
      "     FALSE\n",
      "   └─  Alloy_AZ63A_T6 sand casting\n",
      "     FALSE\n",
      "   └─  10S2O \n",
      "     FALSE\n",
      "   └─  Bronze_C90700_\n",
      "     FALSE\n",
      "   └─  Bronze_C95300_\n",
      "     FALSE\n",
      "   └─  Alloy_Alclad_6061-T451 Wrought\n",
      "     FALSE\n",
      "   └─  11SMn30 \n",
      "     FALSE\n",
      "   └─  cast_iron_class 25 \n",
      "     FALSE\n",
      "   └─  Alloy_3105_H16 Wrought\n",
      "     FALSE\n",
      "   └─  cast_iron_class 50 \n",
      "     FALSE\n",
      "   └─  SAE_1015_as-rolled\n",
      "     TRUE\n",
      "   └─  SAE_1022_normalized\n",
      "     TRUE\n",
      "   └─  SAE_1022_annealed\n",
      "     TRUE\n",
      "   └─  Alloy_C15715_\n",
      "     FALSE\n",
      "   └─  P235GH \n",
      "     FALSE\n",
      "   └─  Bronze_C90300_\n",
      "     FALSE\n",
      "   └─  Alloy_C99750_\n",
      "     FALSE\n",
      "   └─  SAE_1022_as-rolled\n",
      "     TRUE\n",
      "   └─  SPT360 \n",
      "     FALSE\n",
      "   └─  Alloy_C99700_\n",
      "     FALSE\n",
      "   └─  Alloy_C15720_\n",
      "     FALSE\n",
      "   └─  35S20 \n",
      "     FALSE\n",
      "   └─  Alloy_C80100_\n",
      "     FALSE\n",
      "   └─  Alloy_C15000_\n",
      "     FALSE\n",
      "   └─ -Copper_Alloy_C81500 \n",
      "     FALSE\n",
      "   └─  Bronze_C95200_\n",
      "     FALSE\n",
      "   └─  Alloy_4032_T6 Wrought\n",
      "     FALSE\n",
      "   └─  X12CrMnNiN18-9-5 \n",
      "     FALSE\n",
      "   └─ -Copper_Alloy_C81300 \n",
      "     FALSE\n",
      "   └─  Alloy_C15760_\n",
      "     FALSE\n",
      "   └─  Alloy_3105_H25 Wrought\n",
      "     FALSE\n",
      "   └─  Alloy_3105_H14 Wrought\n",
      "     FALSE\n",
      "   └─  S355J2H \n",
      "     TRUE\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import csv\n",
    "def load_csv(filename):\n",
    "    lines=csv.reader(open(filename,\"r\"));\n",
    "    dataset = list(lines)\n",
    "    headers = dataset.pop(0)\n",
    "    return dataset,headers\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,attribute):\n",
    "        self.attribute=attribute\n",
    "        self.children=[]\n",
    "        self.answer=\"\"\n",
    "        \n",
    "def subtables(data,col,delete):\n",
    "    dic={}\n",
    "    coldata=[row[col] for row in data]\n",
    "    attr=list(set(coldata))\n",
    "    \n",
    "    counts=[0]*len(attr)\n",
    "    r=len(data)\n",
    "    c=len(data[0])\n",
    "    for x in range(len(attr)):\n",
    "        for y in range(r):\n",
    "            if data[y][col]==attr[x]:\n",
    "                counts[x]+=1\n",
    "        \n",
    "    for x in range(len(attr)):\n",
    "        dic[attr[x]]=[[0 for i in range(c)] for j in range(counts[x])]\n",
    "        pos=0\n",
    "        for y in range(r):\n",
    "            if data[y][col]==attr[x]:\n",
    "                if delete:\n",
    "                    del data[y][col]\n",
    "                dic[attr[x]][pos]=data[y]\n",
    "                pos+=1\n",
    "    return attr,dic\n",
    "    \n",
    "def entropy(S):\n",
    "    attr=list(set(S))\n",
    "    if len(attr)==1:\n",
    "        return 0\n",
    "    \n",
    "    counts=[0,0]\n",
    "    for i in range(2):\n",
    "        counts[i]=sum([1 for x in S if attr[i]==x])/(len(S)*1.0)\n",
    "    \n",
    "    sums=0\n",
    "    for cnt in counts:\n",
    "        sums+=-1*cnt*math.log(cnt,2)\n",
    "    return sums\n",
    "\n",
    "def compute_gain(data,col):\n",
    "    attr,dic = subtables(data,col,delete=False)\n",
    "    \n",
    "    total_size=len(data)\n",
    "    entropies=[0]*len(attr)\n",
    "    ratio=[0]*len(attr)\n",
    "    \n",
    "    total_entropy=entropy([row[-1] for row in data])\n",
    "    for x in range(len(attr)):\n",
    "        ratio[x]=len(dic[attr[x]])/(total_size*1.0)\n",
    "        entropies[x]=entropy([row[-1] for row in dic[attr[x]]])\n",
    "        total_entropy-=ratio[x]*entropies[x]\n",
    "    return total_entropy\n",
    "\n",
    "def build_tree(data,features):\n",
    "    lastcol=[row[-1] for row in data]\n",
    "    if(len(set(lastcol)))==1:\n",
    "        node=Node(\"\")\n",
    "        node.answer=lastcol[0]\n",
    "        return node\n",
    "    \n",
    "    n=len(data[0])-1\n",
    "    gains=[0]*n\n",
    "    for col in range(n):\n",
    "        gains[col]=compute_gain(data,col)\n",
    "    split=gains.index(max(gains))\n",
    "    node=Node(features[split])\n",
    "    fea = features[:split]+features[split+1:]\n",
    "\n",
    "    \n",
    "    attr,dic=subtables(data,split,delete=True)\n",
    "    \n",
    "    for x in range(len(attr)):\n",
    "        child=build_tree(dic[attr[x]],fea)\n",
    "        node.children.append((attr[x],child))\n",
    "    return node\n",
    "\n",
    "def print_tree(node,level):\n",
    "    if node.answer!=\"\":\n",
    "        print(\"  \"*level,node.answer)\n",
    "        return\n",
    "    \n",
    "    print(\"  \"*level,node.attribute)\n",
    "    for value,n in node.children:\n",
    "        print(\"  \"*(level+1),\"└─\",value)\n",
    "        print_tree(n,level+2)\n",
    "\n",
    "    \n",
    "'''Main program'''\n",
    "dataset,features=load_csv(\"newdata.csv\")\n",
    "node1=build_tree(dataset,features)\n",
    "\n",
    "print(\"The decision tree for the dataset using ID3 algorithm is :\\n\")\n",
    "print_tree(node1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f2cdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
